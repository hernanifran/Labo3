{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../../../sell-in.txt/sell-in.txt', sep='\\t')\n",
    "productosPredecir = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/productos_a_predecir.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "Predicting with LGBM: 100%|██████████| 780/780 [00:02<00:00, 265.89it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convertir el periodo a formato datetime\n",
    "df['periodo'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "\n",
    "# Agregar los datos por periodo y product_id para obtener la serie temporal\n",
    "ts = df.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Asegurarse de que las columnas tengan el mismo tipo y formato\n",
    "ts['product_id'] = ts['product_id'].astype(int)\n",
    "ts['periodo'] = pd.to_datetime(ts['periodo'])\n",
    "\n",
    "# Agregar lags a tus datos\n",
    "lags = 3  # Número de lags a incluir\n",
    "for lag in range(1, lags + 1):\n",
    "    ts[f'tn_lag_{lag}'] = ts.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Eliminar filas con valores nulos resultantes de los lags\n",
    "ts.dropna(inplace=True)\n",
    "\n",
    "# Obtener la lista de productos únicos a predecir\n",
    "product_ids = productosPredecir['product_id'].unique()\n",
    "\n",
    "# Normalizar las series de tiempo (solo 'tn' y lags)\n",
    "scaler_tn = StandardScaler()\n",
    "scaler_lags = StandardScaler()\n",
    "\n",
    "ts[['tn']] = scaler_tn.fit_transform(ts[['tn']])\n",
    "ts[['tn_lag_1', 'tn_lag_2', 'tn_lag_3']] = scaler_lags.fit_transform(ts[['tn_lag_1', 'tn_lag_2', 'tn_lag_3']])\n",
    "\n",
    "# Crear características adicionales si es necesario (Ejemplo: características temporales)\n",
    "ts['year'] = ts['periodo'].dt.year\n",
    "ts['month'] = ts['periodo'].dt.month\n",
    "\n",
    "# Crear conjunto de entrenamiento y objetivo\n",
    "X = ts[['product_id', 'year', 'month'] + [f'tn_lag_{lag}' for lag in range(1, lags + 1)]]  # Puedes agregar más características si están disponibles\n",
    "y = ts['tn']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo LightGBM con Random Forest\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting': 'rf',  # Utilizar Random Forest para generar promedios en el árbol\n",
    "    'num_iterations': 1000,  # Ajustar la cantidad de iteraciones según sea necesario\n",
    "    'learning_rate': 0.003934720226268362,\n",
    "    'num_leaves': 96,\n",
    "    'bagging_freq': 7,  # Frecuencia de bagging\n",
    "    'bagging_fraction': 0.6854002560591308,  # Fracción de bagging\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Entrenamiento de LightGBM con barra de progreso\n",
    "evals_result = {}\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    train_data, \n",
    "    valid_sets=[train_data, test_data], \n",
    "    valid_names=['train', 'valid'],\n",
    "    #evals_result=evals_result,\n",
    "    #early_stopping_rounds=10, \n",
    "    #verbose_eval=10  # Muestra progreso cada 10 iteraciones\n",
    ")\n",
    "\n",
    "# Realizar predicciones para los productos a predecir\n",
    "results = []\n",
    "for product_id in tqdm(product_ids, desc=\"Predicting with LGBM\"):\n",
    "    product_data = ts[ts['product_id'] == product_id].copy()\n",
    "    if not product_data.empty:\n",
    "        # Predicción para el último periodo disponible + 1 mes\n",
    "        last_period = product_data['periodo'].max()\n",
    "        next_period = last_period + pd.DateOffset(months=1)\n",
    "        next_data = pd.DataFrame({\n",
    "            'product_id': [product_id],\n",
    "            'year': [next_period.year],\n",
    "            'month': [next_period.month],\n",
    "            'tn_lag_1': [product_data['tn'].iloc[-1]],\n",
    "            'tn_lag_2': [product_data['tn_lag_1'].iloc[-1]],\n",
    "            'tn_lag_3': [product_data['tn_lag_2'].iloc[-1]]\n",
    "        })\n",
    "        \n",
    "        pred = model.predict(next_data)\n",
    "        results.append({\n",
    "            'product_id': product_id,\n",
    "            'predicted_tn': pred[0]\n",
    "        })\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desnormalizar las predicciones solo de la columna 'predicted_tn'\n",
    "results_df['predicted_tn'] = scaler_tn.inverse_transform(results_df[['predicted_tn']]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones exportadas a 'lgbm_predictionsv2.csv'\n",
      "Root Mean Squared Error: 0.3158682921541013\n",
      "Mean Absolute Error: 0.09488940242040152\n",
      "R² Score: 0.8902636777451165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ajustar predicciones negativas a cero\n",
    "results_df['predicted_tn'] = results_df['predicted_tn'].apply(lambda x: max(x, 0))\n",
    "\n",
    "# Asegurarse de que el DataFrame resultante tiene las columnas product_id y predicted_tn\n",
    "results_df = results_df[['product_id', 'predicted_tn']]\n",
    "\n",
    "# Exportar a un archivo CSV con las columnas product_id y predicted_tn\n",
    "results_df.to_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Predicciones/lgbm_predictionsv2.csv', index=False)\n",
    "\n",
    "print(\"Predicciones exportadas a 'lgbm_predictionsv2.csv'\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R² Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "borrrar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "Predicting with LGBM: 100%|██████████| 780/780 [00:04<00:00, 186.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../../../sell-in.txt/sell-in.txt', sep='\\t')\n",
    "productosPredecir = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/productos_a_predecir.txt', sep='\\t')\n",
    "\n",
    "# Convertir el periodo a formato datetime\n",
    "df['periodo'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "\n",
    "# Agregar los datos por periodo y product_id para obtener la serie temporal\n",
    "ts = df.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Asegurarse de que las columnas tengan el mismo tipo y formato\n",
    "ts['product_id'] = ts['product_id'].astype(int)\n",
    "ts['periodo'] = pd.to_datetime(ts['periodo'])\n",
    "\n",
    "# Agregar lags a tus datos\n",
    "lags = 3  # Número de lags a incluir\n",
    "for lag in range(1, lags + 1):\n",
    "    ts[f'tn_lag_{lag}'] = ts.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Eliminar filas con valores nulos resultantes de los lags\n",
    "ts.dropna(inplace=True)\n",
    "\n",
    "# Obtener la lista de productos únicos a predecir\n",
    "product_ids = productosPredecir['product_id'].unique()\n",
    "\n",
    "# Normalizar las series de tiempo (solo 'tn' y lags)\n",
    "scaler = StandardScaler()\n",
    "ts[['tn', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3']] = scaler.fit_transform(ts[['tn', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3']])\n",
    "\n",
    "# Crear características adicionales si es necesario (Ejemplo: características temporales)\n",
    "ts['year'] = ts['periodo'].dt.year\n",
    "ts['month'] = ts['periodo'].dt.month\n",
    "\n",
    "# Crear conjunto de entrenamiento y objetivo\n",
    "X = ts[['product_id', 'year', 'month'] + [f'tn_lag_{lag}' for lag in range(1, lags + 1)]]  # Puedes agregar más características si están disponibles\n",
    "y = ts['tn']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo LightGBM con Random Forest\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting': 'rf',  # Utilizar Random Forest para generar promedios en el árbol\n",
    "    'num_iterations': 1000,  # Ajustar la cantidad de iteraciones según sea necesario\n",
    "    'learning_rate': 0.003934720226268362,\n",
    "    'num_leaves': 96,\n",
    "    'bagging_freq': 7,  # Frecuencia de bagging\n",
    "    'bagging_fraction': 0.6854002560591308,  # Fracción de bagging\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Entrenamiento de LightGBM con barra de progreso\n",
    "evals_result = {}\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    train_data, \n",
    "    valid_sets=[train_data, test_data], \n",
    "    valid_names=['train', 'valid'],\n",
    "    #evals_result=evals_result,\n",
    "    #early_stopping_rounds=10, \n",
    "    #verbose_eval=10  # Muestra progreso cada 10 iteraciones\n",
    ")\n",
    "\n",
    "# Realizar predicciones para los productos a predecir\n",
    "results = []\n",
    "for product_id in tqdm(product_ids, desc=\"Predicting with LGBM\"):\n",
    "    product_data = ts[ts['product_id'] == product_id].copy()\n",
    "    if not product_data.empty:\n",
    "        # Predicción para el último periodo disponible + 1 mes\n",
    "        last_period = product_data['periodo'].max()\n",
    "        next_period = last_period + pd.DateOffset(months=1)\n",
    "        next_data = pd.DataFrame({\n",
    "            'product_id': [product_id],\n",
    "            'year': [next_period.year],\n",
    "            'month': [next_period.month],\n",
    "            'tn_lag_1': [product_data['tn'].iloc[-1]],\n",
    "            'tn_lag_2': [product_data['tn_lag_1'].iloc[-1]],\n",
    "            'tn_lag_3': [product_data['tn_lag_2'].iloc[-1]]\n",
    "        })\n",
    "        \n",
    "        pred = model.predict(next_data)\n",
    "        results.append({\n",
    "            'product_id': product_id,\n",
    "            'predicted_tn': pred[0]\n",
    "        })\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>10.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>10.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>5.985375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>4.822552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id  predicted_tn\n",
       "0         20001     10.324423\n",
       "1         20002     10.324423\n",
       "2         20003     10.324423\n",
       "3         20004      5.985375\n",
       "4         20005      4.822552\n",
       "..          ...           ...\n",
       "775       21263     -0.372676\n",
       "776       21265     -0.372676\n",
       "777       21266     -0.372676\n",
       "778       21267     -0.372676\n",
       "779       21276     -0.372676\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (780,1) doesn't match the broadcast shape (780,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Desnormalizar las predicciones solo de la columna 'predicted_tn'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_tn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_tn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1103\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1105\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (780,1) doesn't match the broadcast shape (780,4)"
     ]
    }
   ],
   "source": [
    "# Desnormalizar las predicciones solo de la columna 'predicted_tn'\n",
    "results_df['predicted_tn'] = scaler.inverse_transform(results_df[['predicted_tn']]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (78,10) (4,) (78,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Desnormalizar las predicciones\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_tn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_tn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1103\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1105\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (78,10) (4,) (78,10) "
     ]
    }
   ],
   "source": [
    "# Desnormalizar las predicciones\n",
    "results_df['predicted_tn'] = scaler.inverse_transform(results_df['predicted_tn'].values.reshape(-10, 10)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "Predicting with LGBM: 100%|██████████| 780/780 [00:03<00:00, 243.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../../../sell-in.txt/sell-in.txt', sep='\\t')\n",
    "productosPredecir = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/productos_a_predecir.txt', sep='\\t')\n",
    "\n",
    "# Convertir el periodo a formato datetime\n",
    "df['periodo'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "\n",
    "# Agregar los datos por periodo y product_id para obtener la serie temporal\n",
    "ts = df.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Asegurarse de que las columnas tengan el mismo tipo y formato\n",
    "ts['product_id'] = ts['product_id'].astype(int)\n",
    "ts['periodo'] = pd.to_datetime(ts['periodo'])\n",
    "\n",
    "# Agregar lags a tus datos\n",
    "lags = 3  # Número de lags a incluir\n",
    "for lag in range(1, lags + 1):\n",
    "    ts[f'tn_lag_{lag}'] = ts.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Eliminar filas con valores nulos resultantes de los lags\n",
    "ts.dropna(inplace=True)\n",
    "\n",
    "# Obtener la lista de productos únicos a predecir\n",
    "product_ids = productosPredecir['product_id'].unique()\n",
    "\n",
    "# Normalizar las series de tiempo (excepto 'product_id' y 'periodo')\n",
    "scaler = StandardScaler()\n",
    "ts[['tn', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3']] = scaler.fit_transform(ts[['tn', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3']])\n",
    "\n",
    "# Crear características adicionales si es necesario (Ejemplo: características temporales)\n",
    "ts['year'] = ts['periodo'].dt.year\n",
    "ts['month'] = ts['periodo'].dt.month\n",
    "\n",
    "# Crear conjunto de entrenamiento y objetivo\n",
    "X = ts[['product_id', 'year', 'month'] + [f'tn_lag_{lag}' for lag in range(1, lags + 1)]]  # Puedes agregar más características si están disponibles\n",
    "y = ts['tn']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo LightGBM con Random Forest\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting': 'rf',  # Utilizar Random Forest para generar promedios en el árbol\n",
    "    'num_iterations': 1000,  # Ajustar la cantidad de iteraciones según sea necesario\n",
    "    'learning_rate': 0.003934720226268362,\n",
    "    'num_leaves': 96,\n",
    "    'bagging_freq': 7,  # Frecuencia de bagging\n",
    "    'bagging_fraction': 0.6854002560591308,  # Fracción de bagging\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Entrenamiento de LightGBM con barra de progreso\n",
    "evals_result = {}\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    train_data, \n",
    "    valid_sets=[train_data, test_data], \n",
    "    valid_names=['train', 'valid'],\n",
    "    #evals_result=evals_result,\n",
    "    #early_stopping_rounds=10, \n",
    "    #verbose_eval=10  # Muestra progreso cada 10 iteraciones\n",
    ")\n",
    "\n",
    "# Realizar predicciones para los productos a predecir\n",
    "results = []\n",
    "for product_id in tqdm(product_ids, desc=\"Predicting with LGBM\"):\n",
    "    product_data = ts[ts['product_id'] == product_id].copy()\n",
    "    if not product_data.empty:\n",
    "        # Predicción para el último periodo disponible + 1 mes\n",
    "        last_period = product_data['periodo'].max()\n",
    "        next_period = last_period + pd.DateOffset(months=1)\n",
    "        next_data = pd.DataFrame({\n",
    "            'product_id': [product_id],\n",
    "            'year': [next_period.year],\n",
    "            'month': [next_period.month],\n",
    "            'tn_lag_1': [product_data['tn'].iloc[-1]],\n",
    "            'tn_lag_2': [product_data['tn_lag_1'].iloc[-1]],\n",
    "            'tn_lag_3': [product_data['tn_lag_2'].iloc[-1]]\n",
    "        })\n",
    "        \n",
    "        pred = model.predict(next_data)\n",
    "        results.append({\n",
    "            'product_id': product_id,\n",
    "            'predicted_tn': pred[0]\n",
    "        })\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>10.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>10.324423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>5.985375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>4.822552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "      <td>-0.372676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id  predicted_tn\n",
       "0         20001     10.324423\n",
       "1         20002     10.324423\n",
       "2         20003     10.324423\n",
       "3         20004      5.985375\n",
       "4         20005      4.822552\n",
       "..          ...           ...\n",
       "775       21263     -0.372676\n",
       "776       21265     -0.372676\n",
       "777       21266     -0.372676\n",
       "778       21267     -0.372676\n",
       "779       21276     -0.372676\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (78,10) (4,) (78,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Desnormalizar las predicciones\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_tn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_tn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1103\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[0;32m   1105\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (78,10) (4,) (78,10) "
     ]
    }
   ],
   "source": [
    "# Desnormalizar las predicciones\n",
    "results_df['predicted_tn'] = scaler.inverse_transform(results_df['predicted_tn'].values.reshape(-10, 10)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desnormalizar las predicciones\n",
    "results_df['predicted_tn'] = scaler.inverse_transform(results_df['predicted_tn'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Asegurarse de que el DataFrame resultante tiene las columnas product_id y predicted_tn\n",
    "results_df = results_df[['product_id', 'predicted_tn']]\n",
    "\n",
    "# Exportar a un archivo CSV con las columnas product_id y predicted_tn\n",
    "results_df.to_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Predicciones/lgbm_predictionsv2.csv', index=False)\n",
    "\n",
    "print(\"Predicciones exportadas a 'lgbm_predictionsv2.csv'\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
