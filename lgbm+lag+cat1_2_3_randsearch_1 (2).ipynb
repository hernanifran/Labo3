{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "\n",
    "# Desactivar los warnings UndefinedMetricWarning para r2_score\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos(df, tb_productos, lags=12):\n",
    "    # Convertir el periodo a formato datetime\n",
    "    df['periodo'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "\n",
    "    # Agregar los datos por periodo y product_id para obtener la serie temporal\n",
    "    ts = df.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "    # Unir las categorías de productos desde el archivo tb_productos\n",
    "    ts = ts.merge(tb_productos[['product_id', 'cat1', 'cat2', 'cat3']], on='product_id', how='left')\n",
    "\n",
    "    # Convertir las columnas de categoría a tipo 'category'\n",
    "    ts['cat1'] = ts['cat1'].astype('category')\n",
    "    ts['cat2'] = ts['cat2'].astype('category')\n",
    "    ts['cat3'] = ts['cat3'].astype('category')\n",
    "    \n",
    "    # Crear características adicionales\n",
    "    ts['crisis'] = (ts['periodo'].dt.year == 2019) & (ts['periodo'].dt.month == 8)\n",
    "    ts['quarter'] = ts['periodo'].dt.quarter\n",
    "    ts['month'] = ts['periodo'].dt.month\n",
    "\n",
    "    # Normalización por producto\n",
    "    ts['tn_norm'] = ts.groupby('product_id')['tn'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "    # Agregar lags a los datos\n",
    "    for lag in range(1, lags + 1):\n",
    "        ts[f'tn_lag_{lag}'] = ts.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo(ts, lags=12):\n",
    "    # Crear conjunto de entrenamiento y objetivo\n",
    "    X = ts[['product_id', 'cat1', 'cat2','cat3','crisis', 'quarter', 'month'] + [f'tn_lag_{lag}' for lag in range(1, lags + 1)] + ['tn_norm']]\n",
    "    y = ts['tn'].shift(-2)\n",
    "\n",
    "    # Eliminar las últimas 2 filas\n",
    "    X = X.iloc[:-2]\n",
    "    y = y.iloc[:-2]\n",
    "\n",
    "    # Validación temporal en lugar de train_test_split\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    X_train, X_test, y_train, y_test = None, None, None, None\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Codificar las características categóricas 'cat1', 'cat2', 'cat3'\n",
    "    for col in ['cat1', 'cat2', 'cat3']:\n",
    "        X_train[col] = X_train[col].cat.codes\n",
    "        X_test[col] = X_test[col].cat.codes\n",
    "\n",
    "    # Definir el espacio de búsqueda de hiperparámetros\n",
    "    param_dist = {\n",
    "        'num_leaves': [31, 50, 70, 128],\n",
    "        'max_depth': [-1, 10, 20, 30],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'min_child_samples': [20, 30, 40],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # Definir el modelo de LightGBM con RandomizedSearchCV\n",
    "    lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "    random_search = RandomizedSearchCV(lgb_model, param_distributions=param_dist, n_iter=100, cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "    # Crear y ajustar el modelo de Random Forest\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Crear y ajustar el modelo de XGBoost\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener el mejor modelo de LightGBM\n",
    "    lgb_model = random_search.best_estimator_\n",
    "\n",
    "    # Crear el modelo de ensemble\n",
    "    ensemble_model = VotingRegressor(estimators=[\n",
    "        ('lgb', lgb_model),\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model)\n",
    "    ])\n",
    "\n",
    "    # Ajustar el modelo de ensemble\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de rendimiento\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Ensemble Model MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    return ensemble_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_producto(ensemble_model, ts, product_ids, next_period='2020-02-01', lags=12):\n",
    "    next_period = pd.Timestamp(next_period)\n",
    "    results = []\n",
    "\n",
    "    for product_id in tqdm(product_ids, desc=\"Predicting with ensemble model\"):\n",
    "        product_data = ts[ts['product_id'] == product_id].copy()\n",
    "        if not product_data.empty:\n",
    "            last_data = product_data.iloc[-1]\n",
    "\n",
    "            # Convertir a categoría si es list-like\n",
    "            try:\n",
    "                cat1 = pd.Categorical(last_data['cat1'])\n",
    "                cat2 = pd.Categorical(last_data['cat2'])\n",
    "                cat3 = pd.Categorical(last_data['cat3'])\n",
    "            except TypeError:\n",
    "                cat1, cat2, cat3 = None, None, None\n",
    "\n",
    "            if cat1 is not None and cat2 is not None and cat3 is not None:\n",
    "                # Construir datos para la predicción\n",
    "                next_data = pd.DataFrame({\n",
    "                    'product_id': [product_id],\n",
    "                    'cat1': [cat1.codes[0] if len(cat1) > 0 else 0],\n",
    "                    'cat2': [cat2.codes[0] if len(cat2) > 0 else 0],\n",
    "                    'cat3': [cat3.codes[0] if len(cat3) > 0 else 0],\n",
    "                    'crisis': [(next_period.year == 2019) & (next_period.month == 8)],\n",
    "                    'quarter': [next_period.quarter],\n",
    "                    'month': [next_period.month],\n",
    "                    **{f'tn_lag_{lag}': [last_data[f'tn_lag_{lag}']] if f'tn_lag_{lag}' in product_data.columns else [0] for lag in range(1, lags + 1)},\n",
    "                    'tn_norm': [0]  # Ajustar tn_norm adecuadamente si es necesario\n",
    "                })\n",
    "\n",
    "                # Predecir usando el modelo de ensemble\n",
    "                pred = ensemble_model.predict(next_data)\n",
    "                results.append({'product_id': product_id, 'predicted_tn': pred[0]})\n",
    "            else:\n",
    "                product_mean_tn = ts[ts['product_id'] == product_id]['tn'].mean()\n",
    "                if not pd.isna(product_mean_tn):\n",
    "                    results.append({'product_id': product_id, 'predicted_tn': product_mean_tn})\n",
    "                else:\n",
    "                    global_mean_tn = ts['tn'].mean()\n",
    "                    results.append({'product_id': product_id, 'predicted_tn': global_mean_tn})\n",
    "        else:\n",
    "            product_mean_tn = ts[ts['product_id'] == product_id]['tn'].mean()\n",
    "            if not pd.isna(product_mean_tn):\n",
    "                results.append({'product_id': product_id, 'predicted_tn': product_mean_tn})\n",
    "            else:\n",
    "                global_mean_tn = ts['tn'].mean()\n",
    "                results.append({'product_id': product_id, 'predicted_tn': global_mean_tn})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_metricas(df, results_df, target_date='2019-12-01'):\n",
    "    df['date'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "    df_filtered = df[df['date'] == target_date]\n",
    "    results_df_ajustado = results_df.groupby('product_id')['predicted_tn'].sum()\n",
    "\n",
    "    metricas_por_producto = []\n",
    "    numerador = 0\n",
    "    denominator = 0\n",
    "\n",
    "    for product_id in df_filtered['product_id'].unique():\n",
    "        if product_id in results_df_ajustado.index:\n",
    "            y_true = df_filtered.loc[df_filtered['product_id'] == product_id, 'tn'].values[0]\n",
    "            y_pred = results_df_ajustado.loc[product_id]\n",
    "            numerador += abs(y_true - y_pred)\n",
    "            denominator += y_true\n",
    "            rmse = np.sqrt(mean_squared_error([y_true], [y_pred]))\n",
    "            mae = mean_absolute_error([y_true], [y_pred])\n",
    "            r2 = r2_score([y_true], [y_pred]) if len([y_true]) > 1 and len([y_pred]) > 1 else float('nan')\n",
    "            metricas_por_producto.append({\n",
    "                'product_id': product_id,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'r2': r2\n",
    "            })\n",
    "\n",
    "    if metricas_por_producto:\n",
    "        avg_rmse = np.mean([m['rmse'] for m in metricas_por_producto])\n",
    "        avg_mae = np.mean([m['mae'] for m in metricas_por_producto])\n",
    "        avg_r2 = np.nanmean([m['r2'] for m in metricas_por_producto])\n",
    "        metricas_por_producto.append({\n",
    "            'product_id': 'average',\n",
    "            'rmse': avg_rmse,\n",
    "            'mae': avg_mae,\n",
    "            'r2': avg_r2\n",
    "        })\n",
    "\n",
    "    metricas_df = pd.DataFrame(metricas_por_producto)\n",
    "    metricaMultinacion = numerador / denominator\n",
    "    print(\"Métrica multinacional\", metricaMultinacion)\n",
    "    print(\"metrica multinacional\", metricaMultinacion)\n",
    "    print(\"rmse: \", metricas_df['rmse'].mean())\n",
    "    print(\"mae: \", metricas_df['mae'].mean())\n",
    "    print(\"r2: \", metricas_df['r2'].mean())\n",
    "\n",
    "    # Exportar métricas a un archivo CSV\n",
    "    metricas_df.to_csv('metricas_por_producto.csv', index=False)\n",
    "    print(f\"Métricas por producto exportadas a 'metricas_por_producto.csv'\")\n",
    "    \n",
    "    return metricas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../../../sell-in.txt/sell-in.txt', sep='\\t')\n",
    "productosPredecir = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/productos_a_predecir.txt', sep='\\t')\n",
    "tb_productos = pd.read_csv('c:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/tb_productos_descripcion.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = preparar_datos(df, tb_productos, lags=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción sobre febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20001, 20002, 20003, ..., 21267, 21271, 21276], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productosPredecir = ts['product_id'].values\n",
    "productosPredecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro por producto 20005 y periodo menor a 2019-11-01\n",
    "#productoPrueba = [20001,20002,20003,20004,20005,20006,20007,20008,20009,20010,20011,20012]\n",
    "# Convertir cada elemento a int64\n",
    "#productoPrueba_int64 = [np.int64(x) for x in productosPredecir]\n",
    "#ts = ts[ts['product_id'] == productoPrueba].copy()\n",
    "#ts = ts[ts['periodo'] < '2019-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josvaldes\\AppData\\Local\\Temp\\ipykernel_31512\\2656096673.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].cat.codes\n",
      "C:\\Users\\Josvaldes\\AppData\\Local\\Temp\\ipykernel_31512\\2656096673.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3695\n",
      "[LightGBM] [Info] Number of data points in the train set: 26035, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 44.668985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found: {'subsample': 0.8, 'num_leaves': 128, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 20, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3695\n",
      "[LightGBM] [Info] Number of data points in the train set: 26035, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 44.668985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Ensemble Model MSE: 3737.9477, MAE: 15.1570, R²: 0.5953\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = entrenar_modelo(ts, lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with ensemble model: 100%|██████████| 31243/31243 [00:54<00:00, 576.45it/s]\n"
     ]
    }
   ],
   "source": [
    "result_df = predecir_producto(ensemble_model, ts, productosPredecir, next_period='2020-02-01', lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id  predicted_tn\n",
      "0           20001   1398.344322\n",
      "1           20002   1009.368178\n",
      "2           20003    889.004243\n",
      "3           20004    671.615383\n",
      "4           20005    644.200514\n",
      "...           ...           ...\n",
      "31238       21265      0.089541\n",
      "31239       21266      0.094659\n",
      "31240       21267      0.092835\n",
      "31241       21271      0.026964\n",
      "31242       21276      0.045447\n",
      "\n",
      "[31243 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id  predicted_tn\n",
      "0           20001   1398.344322\n",
      "36          20002   1009.368178\n",
      "72          20003    889.004243\n",
      "108         20004    671.615383\n",
      "144         20005    644.200514\n",
      "...           ...           ...\n",
      "22294       21263      0.089233\n",
      "22309       21265      0.089541\n",
      "22319       21266      0.094659\n",
      "22329       21267      0.092835\n",
      "22339       21276      0.045447\n",
      "\n",
      "[780 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "productosPredecir = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/productos_a_predecir.txt', sep='\\t')\n",
    "\n",
    "# Asegúrate de que la columna 'product_id' en ambos DataFrames sea del mismo tipo\n",
    "result_df['product_id'] = result_df['product_id'].astype(int)\n",
    "productosPredecir['product_id'] = productosPredecir['product_id'].astype(int)\n",
    "\n",
    "# Realiza un merge para obtener solo los productos predichos que están en productosPredecir\n",
    "predicted_products = pd.merge(productosPredecir, result_df, on='product_id', how='inner')\n",
    "\n",
    "# Eliminar duplicados para asegurarse de tener un producto único\n",
    "predicted_products = predicted_products.drop_duplicates(subset=['product_id'])\n",
    "\n",
    "# Verifica el resultado\n",
    "print(predicted_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_products.to_csv('resultadosPredichos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación sobre diciembre 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = preparar_datos(df, tb_productos, lags=12)\n",
    "ts = ts[ts['periodo'] < '2019-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir cada elemento a int64\n",
    "#productoPrueba_int64 = [np.int64(x) for x in productosPredecir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josvaldes\\AppData\\Local\\Temp\\ipykernel_31512\\2656096673.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].cat.codes\n",
      "C:\\Users\\Josvaldes\\AppData\\Local\\Temp\\ipykernel_31512\\2656096673.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3694\n",
      "[LightGBM] [Info] Number of data points in the train set: 24480, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 44.852583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found: {'subsample': 0.8, 'num_leaves': 128, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': 20, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3694\n",
      "[LightGBM] [Info] Number of data points in the train set: 24480, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 44.852583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Ensemble Model MSE: 4364.1265, MAE: 16.2146, R²: 0.5556\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = entrenar_modelo(ts, lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with ensemble model:   0%|          | 1/780 [00:00<00:03, 221.44it/s]\n"
     ]
    }
   ],
   "source": [
    "result_df = predecir_producto(ensemble_model, ts, productosPredecir, next_period='2019-12-01', lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_id</td>\n",
       "      <td>43.052861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  predicted_tn\n",
       "0  product_id     43.052861"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "productosPredecir = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Datasets/productos_a_predecir.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id\n",
       "0         20001\n",
       "1         20002\n",
       "2         20003\n",
       "3         20004\n",
       "4         20005\n",
       "..          ...\n",
       "775       21263\n",
       "776       21265\n",
       "777       21266\n",
       "778       21267\n",
       "779       21276\n",
       "\n",
       "[780 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productosPredecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'product_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Asegúrate de que la columna 'product_id' en ambos DataFrames sea del mismo tipo\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mresult_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduct_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m productosPredecir[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m productosPredecir[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Realiza un merge para obtener solo los productos predichos que están en productosPredecir\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Josvaldes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'product_id'"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que la columna 'product_id' en ambos DataFrames sea del mismo tipo\n",
    "result_df['product_id'] = result_df['product_id'].astype(int)\n",
    "productosPredecir['product_id'] = productosPredecir['product_id'].astype(int)\n",
    "\n",
    "# Realiza un merge para obtener solo los productos predichos que están en productosPredecir\n",
    "predicted_products = pd.merge(productosPredecir, result_df, on='product_id', how='inner')\n",
    "\n",
    "# Eliminar duplicados para asegurarse de tener un producto único\n",
    "predicted_products = predicted_products.drop_duplicates(subset=['product_id'])\n",
    "\n",
    "# Verifica el resultado\n",
    "print(predicted_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = preparar_datos(df, tb_productos, lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_id  predicted_tn     real_tn  metricaempresa\n",
      "0          20001   1395.245139  1504.68856        0.072735\n",
      "1          20002    994.893190  1087.30855        0.084995\n",
      "2          20003    887.157574   892.50129        0.005987\n",
      "3          20004    671.067991   637.90002        0.051996\n",
      "4          20005    646.795952   593.24443        0.090269\n",
      "...          ...           ...         ...             ...\n",
      "1185       20962      5.317000     1.99182        1.669418\n",
      "1186       20975      4.981210     1.69045        1.946677\n",
      "1187       20995      4.624140     1.55285        1.977841\n",
      "1188       21087      0.603995     1.02205        0.409036\n",
      "1189       21214      0.279925     0.24428        0.145919\n",
      "\n",
      "[780 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Filtrar el DataFrame 'ts' para obtener los datos del período específico y los productos a predecir\n",
    "filtered_df = ts[(ts['periodo'] == '2019-12-01') & (ts['product_id'].isin(productosPredecir['product_id']))]\n",
    "\n",
    "# Paso 2: Agrupar los datos filtrados por 'product_id' y calcular la suma de 'tn' para cada producto\n",
    "real_tn = filtered_df.groupby('product_id')['tn'].sum()\n",
    "\n",
    "# Paso 3: Eliminar duplicados en 'result_df' para asegurar que cada producto aparezca una vez\n",
    "result_df_unique = result_df.drop_duplicates(subset='product_id')\n",
    "\n",
    "# Paso 4: Realizar un merge para asegurar que los 'product_id' coincidan en 'result_df' y 'real_tn'\n",
    "result_df_unique = result_df_unique.merge(real_tn.rename('real_tn'), on='product_id', how='left')\n",
    "\n",
    "# Paso 5: Calcular la métrica de la empresa por producto\n",
    "result_df_unique['metricaempresa'] = abs(result_df_unique['real_tn'] - result_df_unique['predicted_tn']) / result_df_unique['real_tn']\n",
    "\n",
    "# Paso 6: Filtrar 'result_df_unique' para obtener solo los productos que están en 'productosPredecir'\n",
    "final_result_df = result_df_unique[result_df_unique['product_id'].isin(productosPredecir['product_id'])]\n",
    "\n",
    "# Imprimir el resultado final\n",
    "print(final_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métrica multinacional 5095.06489170038\n",
      "metrica multinacional 5095.06489170038\n",
      "rmse:  1306.1396166842176\n",
      "mae:  1306.1396166842176\n",
      "r2:  nan\n",
      "Métricas por producto exportadas a 'metricas_por_producto.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josvaldes\\AppData\\Local\\Temp\\ipykernel_31512\\4073115482.py:29: RuntimeWarning: Mean of empty slice\n",
      "  avg_r2 = np.nanmean([m['r2'] for m in metricas_por_producto])\n"
     ]
    }
   ],
   "source": [
    "metrica = evaluar_metricas(df, result_df, target_date='2019-12-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_df.to_csv('validacionDic23.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segunda iteración con productos que tiene una metrica de la empresa superior al 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_id  predicted_tn    real_tn  metricaempresa\n",
      "5          20006    596.232753  417.23228        0.429019\n",
      "6          20007    625.592909  390.43432        0.602300\n",
      "7          20008    569.306666  195.36854        1.914014\n",
      "9          20010    524.720959  359.59998        0.459180\n",
      "10         20011    452.907964  392.38290        0.154250\n",
      "...          ...           ...        ...             ...\n",
      "1185       20962      5.317000    1.99182        1.669418\n",
      "1186       20975      4.981210    1.69045        1.946677\n",
      "1187       20995      4.624140    1.55285        1.977841\n",
      "1188       21087      0.603995    1.02205        0.409036\n",
      "1189       21214      0.279925    0.24428        0.145919\n",
      "\n",
      "[689 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame usando la función query\n",
    "SegundaIteracion_result_df = final_result_df.query('metricaempresa > 0.10')\n",
    "\n",
    "# Imprimir el resultado filtrado\n",
    "print(SegundaIteracion_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>predicted_tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1395.245139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>994.893190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>887.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>671.067991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>646.795952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31238</th>\n",
       "      <td>21265</td>\n",
       "      <td>0.097417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31239</th>\n",
       "      <td>21266</td>\n",
       "      <td>0.103531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31240</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.109018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31241</th>\n",
       "      <td>21271</td>\n",
       "      <td>0.028482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31242</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.051518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  predicted_tn\n",
       "0           20001   1395.245139\n",
       "1           20002    994.893190\n",
       "2           20003    887.157574\n",
       "3           20004    671.067991\n",
       "4           20005    646.795952\n",
       "...           ...           ...\n",
       "31238       21265      0.097417\n",
       "31239       21266      0.103531\n",
       "31240       21267      0.109018\n",
       "31241       21271      0.028482\n",
       "31242       21276      0.051518\n",
       "\n",
       "[31243 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_id  predicted_tn     real_tn  metricaempresa\n",
      "0          20001   1395.245139  1504.68856        0.072735\n",
      "1          20002    994.893190  1087.30855        0.084995\n",
      "2          20003    887.157574   892.50129        0.005987\n",
      "3          20004    671.067991   637.90002        0.051996\n",
      "4          20005    646.795952   593.24443        0.090269\n",
      "...          ...           ...         ...             ...\n",
      "1160       21035      1.756772     1.80884        0.028785\n",
      "1161       21039      2.100980     1.94374        0.080896\n",
      "1167       20694      8.357723     8.90416        0.061369\n",
      "1168       20762      6.762283     6.82849        0.009696\n",
      "1174       21097      1.281353     1.34469        0.047101\n",
      "\n",
      "[91 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame usando la función query\n",
    "listadoProductosFinal_result_df_1 = final_result_df.query('metricaempresa < 0.10')\n",
    "\n",
    "predicted_products = pd.read_csv('C:/Users/Josvaldes/Documents/Maestria/Austral/2ano/Labo3/datasets/Proyecto/Labo3/Predicciones/resultadosPredichos.csv', sep='\\t')\n",
    "\n",
    "# Asegúrate de que la columna 'product_id' en ambos DataFrames sea del mismo tipo\n",
    "predicted_products['product_id'] = predicted_products['product_id'].astype(int)\n",
    "listadoProductosFinal_result_df_1['product_id'] = listadoProductosFinal_result_df_1['product_id'].astype(int)\n",
    "\n",
    "# Realiza un merge para obtener solo los productos predichos que están en productosPredecir\n",
    "listadoProductosFinal_result_df_1 = pd.merge(listadoProductosFinal_result_df_1, predicted_products, on='product_id', how='inner')\n",
    "\n",
    "# Eliminar duplicados para asegurarse de tener un producto único\n",
    "#listadoProductosFinal_result_df_1 = predicted_products.drop_duplicates(subset=['product_id'])\n",
    "\n",
    "# Verifica el resultado\n",
    "print(listadoProductosFinal_result_df_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
